{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f59f266-c0ae-421f-9dd1-2a7ff6148c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from decimal import Decimal\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7986f0af-6485-44ef-8759-28143ea53b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_parquet('ekubo_market_depth_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ae609e-97c0-4056-a595-107fc060578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ori.copy()\n",
    "\n",
    "# Compute timestamp:\n",
    "df['datetime'] = pd.to_datetime(df_ori['BLOCK_TIMESTAMP'])\n",
    "df['timestamp'] = df['datetime'].astype('int64') // 10**9  # Convert nanoseconds to seconds\n",
    "df = df.sort_values(by='timestamp')\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Obtain names of Token0 and Token1:\n",
    "\n",
    "# Tag different token address:\n",
    "# Token0\n",
    "# ETH: 0x049d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\n",
    "# USDC: 0x053c91253bc9682c04929ca02ed00b3e423f6710d2ee7e0d5ebb06f3ecf368a8\n",
    "# STRK: 0x04718f5a0fc34cc1af16a1cdee98ffb20c31f5cd61d6ab07201858f4287c938d\n",
    "\n",
    "# Token1\n",
    "# ETH: 0x049d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7\n",
    "# USDC: 0x053c91253bc9682c04929ca02ed00b3e423f6710d2ee7e0d5ebb06f3ecf368a8\n",
    "# USDT: 0x068f5c6a61780768455de69077e07e89787839bf8166decfbf92b645209c0fb8\n",
    "df['Token0_name'] = ''\n",
    "df['Token1_name'] = ''\n",
    "\n",
    "address = '0x049d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7'\n",
    "df.loc[df['TOKEN0_ADDRESS'] == address, 'Token0_name'] = 'ETH'\n",
    "\n",
    "address = '0x053c91253bc9682c04929ca02ed00b3e423f6710d2ee7e0d5ebb06f3ecf368a8'\n",
    "df.loc[df['TOKEN0_ADDRESS'] == address, 'Token0_name'] = 'USDC'\n",
    "\n",
    "address = '0x04718f5a0fc34cc1af16a1cdee98ffb20c31f5cd61d6ab07201858f4287c938d'\n",
    "df.loc[df['TOKEN0_ADDRESS'] == address, 'Token0_name'] = 'STRK'\n",
    "\n",
    "address = '0x049d36570d4e46f48e99674bd3fcc84644ddd6b96f7c741b1562b82f9e004dc7'\n",
    "df.loc[df['TOKEN1_ADDRESS'] == address, 'Token1_name'] = 'ETH'\n",
    "\n",
    "address = '0x053c91253bc9682c04929ca02ed00b3e423f6710d2ee7e0d5ebb06f3ecf368a8'\n",
    "df.loc[df['TOKEN1_ADDRESS'] == address, 'Token1_name'] = 'USDC'\n",
    "\n",
    "address = '0x068f5c6a61780768455de69077e07e89787839bf8166decfbf92b645209c0fb8'\n",
    "df.loc[df['TOKEN1_ADDRESS'] == address, 'Token1_name'] = 'USDT'\n",
    "\n",
    "\n",
    "# Convert each column to either int or float:\n",
    "columns_int = ['BLOCK_NUMBER', 'TOKEN0_DECIMALS', 'TOKEN1_DECIMALS', 'TICK_SPACING']\n",
    "df[columns_int] = df[columns_int].applymap(lambda x: int(x))\n",
    "\n",
    "columns_float = ['TOKEN0_RAW_AMOUNT', 'TOKEN0_REAL_AMOUNT', 'TOKEN1_RAW_AMOUNT', 'TOKEN1_REAL_AMOUNT',\n",
    "                 'FEE_TIER', 'LIQUIDITY_AMOUNT', 'LOWER_TICK', 'UPPER_TICK', 'SWAP_TICK']\n",
    "df[columns_float] = df[columns_float].applymap(lambda x: float(x))\n",
    "\n",
    "# Create a 'tag' column for 'token0_token1'\n",
    "df['tag'] = df['Token0_name']+'_'+df['Token1_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b965011-18fa-47e8-85dc-f8913964fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_aggregation(df2_input, columns_agg, tag, agg_type):\n",
    "    ''' This is the function to compute and obtain daily aggregations inforamtion. \n",
    "    '''\n",
    "    # Seperate input df to 'mint', 'burn', and 'swap'\n",
    "    df2_input_mint = df2_input[df2_input['EVENT_NAME']=='Mint']\n",
    "    df2_input_burn = df2_input[df2_input['EVENT_NAME']=='Burn']\n",
    "    df2_input_swap = df2_input[df2_input['EVENT_NAME']=='Swap']\n",
    "    \n",
    "    # Obtain general daily information\n",
    "    df2_output = pd.DataFrame(columns=columns_agg, index=[0])\n",
    "    \n",
    "    df2_output['tag'] = df2_input['tag'].iloc[0]\n",
    "    \n",
    "    if agg_type=='daily':\n",
    "        df2_output['date'] = pd.Timestamp(df2_input['datetime'].dt.date.iloc[0])\n",
    "    elif agg_type=='hourly':\n",
    "        df2_output['date'] = df2_input['datetime'].dt.round('60min').iloc[0]\n",
    "    \n",
    "    df2_output['timestamp'] = (df2_output['date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    \n",
    "    df2_output['token0'] = df2_input['Token0_name'].iloc[0]\n",
    "    df2_output['token1'] = df2_input['Token1_name'].iloc[0]\n",
    "    \n",
    "    df2_output['total_events_daily_mint'] = len(df2_input_mint)\n",
    "    df2_output['total_events_daily_burn'] = len(df2_input_burn)\n",
    "    df2_output['total_events_daily_swap'] = len(df2_input_swap)\n",
    "    df2_output['total_events_daily'] = len(df2_input_mint) + len(df2_input_burn) + len(df2_input_swap)\n",
    "\n",
    "    # Compute 'mint' and 'burn'\n",
    "    if len(df2_input_mint)>0:\n",
    "        df2_output_tmp_mint = _compute_daily_price_amount(df2_input_mint)\n",
    "        if len(df2_output_tmp_mint)>0:\n",
    "            df2_output['token0_daily_price_median_mint']  = df2_output_tmp_mint['price_token0_daily'].iloc[0]\n",
    "            df2_output['token0_daily_amount_mint'] = df2_output_tmp_mint['amount_token0_daily'].iloc[0]\n",
    "            df2_output['liquidity_daily_sum_mint'] = df2_output_tmp_mint['liquidity_daily_sum'].iloc[0]\n",
    "        else:\n",
    "            df2_output['token0_daily_price_median_mint']  = np.nan\n",
    "            df2_output['token0_daily_amount_mint'] = 0\n",
    "            df2_output['liquidity_daily_sum_mint'] = 0            \n",
    "    else:\n",
    "        df2_output['token0_daily_price_median_mint']  = np.nan\n",
    "        df2_output['token0_daily_amount_mint'] = 0\n",
    "        df2_output['liquidity_daily_sum_mint'] = 0\n",
    "\n",
    "    if len(df2_input_burn)>0:\n",
    "        df2_output_tmp_burn = _compute_daily_price_amount(df2_input_burn)\n",
    "        if len(df2_output_tmp_burn)>0:\n",
    "            df2_output['token0_daily_price_median_burn']  = df2_output_tmp_burn['price_token0_daily'].iloc[0]\n",
    "            df2_output['token0_daily_amount_burn'] = df2_output_tmp_burn['amount_token0_daily'].iloc[0]\n",
    "            df2_output['liquidity_daily_sum_burn'] = df2_output_tmp_burn['liquidity_daily_sum'].iloc[0]\n",
    "        else:\n",
    "            df2_output['token0_daily_price_median_burn']  = np.nan\n",
    "            df2_output['token0_daily_amount_burn'] = 0\n",
    "            df2_output['liquidity_daily_sum_burn'] = 0            \n",
    "    else:\n",
    "        df2_output['token0_daily_price_median_burn']  = np.nan\n",
    "        df2_output['token0_daily_amount_burn'] = 0\n",
    "        df2_output['liquidity_daily_sum_burn'] = 0\n",
    "\n",
    "    df2_output['token0_daily_amount_net_mint_burn'] = df2_output['token0_daily_amount_mint'] + df2_output['token0_daily_amount_burn']\n",
    "    df2_output['liquidity_daily_net_mint_burn'] = df2_output['liquidity_daily_sum_mint'] + df2_output['liquidity_daily_sum_burn']\n",
    "        \n",
    "    # Compute 'swap':\n",
    "    if len(df2_input_swap)>0:\n",
    "        df2_output_tmp_swap = _compute_daily_price_amount(df2_input_swap)\n",
    "        if len(df2_output_tmp_swap)>0:\n",
    "            df2_output['token0_daily_price_median_swap'] = abs(df2_output_tmp_swap['ratio_token1_token0'].median())\n",
    "            df2_output['token0_daily_price_min_swap']  = abs(df2_output_tmp_swap['ratio_token1_token0'].min())\n",
    "            df2_output['token0_daily_price_max_swap']  = abs(df2_output_tmp_swap['ratio_token1_token0'].max())\n",
    "            df2_output['token0_daily_price_std_swap']  = abs(df2_output_tmp_swap['ratio_token1_token0'].std())\n",
    "        \n",
    "            df2_output['token0_daily_amount_buy_swap']  = df2_output_tmp_swap['token0_daily_swap_buy'].iloc[0]\n",
    "            df2_output['token0_daily_amount_sell_swap'] = df2_output_tmp_swap['token0_daily_swap_sell'].iloc[0]\n",
    "            df2_output['token0_daily_amount_net_swap']  = df2_output['token0_daily_amount_buy_swap'] + df2_output['token0_daily_amount_sell_swap']\n",
    "            # df_new['token0_daily_volumn_buy_swap_inUSD'] = df_new['token0_daily_price_median_swap'] * df_new['token0_daily_amount_buy_swap']\n",
    "            # df_new['token0_daily_volumn_sell_swap_inUSD'] = df_new['token0_daily_price_median_swap'] * df_new['token0_daily_amount_sell_swap']\n",
    "            # df_new['token0_daily_volumn_net_swap_inUSD'] = df_new['token0_daily_volumn_buy_swap_inUSD'] + df_new['token0_daily_volumn_net_swap_inUSD']\n",
    "        else:\n",
    "            df2_output['token0_daily_price_median_swap'] = np.nan\n",
    "            df2_output['token0_daily_price_min_swap']  = np.nan\n",
    "            df2_output['token0_daily_price_max_swap']  = np.nan\n",
    "            df2_output['token0_daily_price_std_swap']  = np.nan\n",
    "            df2_output['token0_daily_amount_buy_swap']  = np.nan\n",
    "            df2_output['token0_daily_amount_sell_swap'] = np.nan\n",
    "            df2_output['token0_daily_amount_net_swap']  = np.nan            \n",
    "    else:\n",
    "        df2_output['token0_daily_price_median_swap'] = np.nan\n",
    "        df2_output['token0_daily_price_min_swap']  = np.nan\n",
    "        df2_output['token0_daily_price_max_swap']  = np.nan\n",
    "        df2_output['token0_daily_price_std_swap']  = np.nan\n",
    "        df2_output['token0_daily_amount_buy_swap']  = np.nan\n",
    "        df2_output['token0_daily_amount_sell_swap'] = np.nan\n",
    "        df2_output['token0_daily_amount_net_swap']  = np.nan\n",
    "    # Compute 'LIQUIDITY_AMOUNT' for 'Mint' and 'Burn' only:\n",
    "    # df_new['liquidity_amount_sum'] = df_day['LIQUIDITY_AMOUNT'].sum()    \n",
    "        \n",
    "    df2_output = df2_output.sort_values(by='timestamp')\n",
    "    df2_output = df2_output.reset_index(drop=True)\n",
    "    return df2_output\n",
    "    \n",
    "###################################################################################################\n",
    "def _compute_daily_price_amount(df_day_input):\n",
    "    ''' To compute Token0 daily price and amount:\n",
    "        Method: \n",
    "        Individual event price: 'TOKEN1_REAL_AMOUNT' / 'TOKEN0_REAL_AMOUNT'\n",
    "        The final daily price '''\n",
    "    df_day_output = pd.DataFrame()\n",
    "    df_day_output['ratio_token1_token0'] = df_day_input['TOKEN1_REAL_AMOUNT']/df_day_input['TOKEN0_REAL_AMOUNT'] # Compute TOKEN1_REAL_AMOUNT/TOKEN0_REAL_AMOUNT\n",
    "    df_day_output['TOKEN0_REAL_AMOUNT'] = df_day_input['TOKEN0_REAL_AMOUNT']     \n",
    "    df_day_output = df_day_output[(df_day_output != 0) & (df_day_output != np.inf) & (df_day_output != -np.inf)].dropna() # Remove rows with 0, inf, or -inf values\n",
    "\n",
    "    # Below only apply to 'mint' and 'burn'\n",
    "    if (df_day_input['EVENT_NAME'].iloc[0]=='Mint') | (df_day_input['EVENT_NAME'].iloc[0]=='Burn'):\n",
    "        # df_day_output['percentage'] = df_day_output['TOKEN0_REAL_AMOUNT']/df_day_output['TOKEN0_REAL_AMOUNT'].sum()\n",
    "        # df_day_output['price_token0_daily'] = np.sum(df_day_output['ratio_token1_token0']*df_day_output['percentage'])\n",
    "        df_day_output['price_token0_daily'] = df_day_output['ratio_token1_token0'].median()\n",
    "        df_day_output['amount_token0_daily'] = df_day_output['TOKEN0_REAL_AMOUNT'].sum()\n",
    "        df_day_output['liquidity_daily_sum'] = df_day_input['LIQUIDITY_AMOUNT'].sum()\n",
    "\n",
    "    # Below only apply to 'swap'\n",
    "    if df_day_input['EVENT_NAME'].iloc[0]=='Swap':\n",
    "        df_day_output['token0_daily_swap_buy']   = df_day_input[df_day_input['TOKEN0_REAL_AMOUNT']>0]['TOKEN0_REAL_AMOUNT'].sum()\n",
    "        df_day_output['token0_daily_swap_sell']  = df_day_input[df_day_input['TOKEN0_REAL_AMOUNT']<0]['TOKEN0_REAL_AMOUNT'].sum()\n",
    "        df_day_output['token0_daily_swap_total'] = df_day_output['token0_daily_swap_buy'] + df_day_output['token0_daily_swap_sell']\n",
    "\n",
    "    return df_day_output\n",
    "\n",
    "###################################################################################################\n",
    "def _generate_datetime_range(df2, agg_type):\n",
    "    ''' Obatin a list with 'daily' or 'hourly' from the selected dataframe ''' \n",
    "    # Obtain the begin and end date of selected dataframe\n",
    "    dt_begin = df2['datetime'].iloc[0]\n",
    "    dt_end   = df2['datetime'].iloc[-1]\n",
    "    d_begin = dt_begin.date()\n",
    "    d_end   = dt_end.date() + timedelta(days=1)\n",
    "    if agg_type=='daily':\n",
    "        datetime_range = pd.date_range(start=d_begin, end=d_end)\n",
    "    elif agg_type=='hourly':\n",
    "        datetime_range = pd.date_range(start=d_begin, end=d_end, freq='H')\n",
    "    return datetime_range\n",
    "        \n",
    "###################################################################################################\n",
    "def create_aggregation_table(df, tags, agg_type):\n",
    "    # Create an empty dataframe with defaulted column names \n",
    "    columns_agg = ['tag', 'token0', 'token1', \n",
    "                   'date', 'timestamp', \n",
    "                   \n",
    "                   'token0_daily_price_median_mint', 'token0_daily_amount_mint', \n",
    "                   'token0_daily_price_median_burn', 'token0_daily_amount_burn', \n",
    "                   'token0_daily_amount_net_mint_burn',\n",
    "                   \n",
    "                   'liquidity_daily_sum_mint', 'liquidity_daily_sum_burn', 'liquidity_daily_net_mint_burn',\n",
    "                   \n",
    "                   'token0_daily_price_median_swap', 'token0_daily_price_min_swap', \n",
    "                   'token0_daily_price_max_swap', 'token0_daily_price_std_swap',\n",
    "                   \n",
    "                   'token0_daily_amount_buy_swap', 'token0_daily_amount_sell_swap', 'token0_daily_amount_net_swap',\n",
    "                   # 'token0_daily_volumn_buy_swap_inUSD', 'token0_daily_volumn_sell_swap_inUSD', 'token0_daily_volumn_net_swap_inUSD',\n",
    "                   \n",
    "                   'total_events_daily_mint', 'total_events_daily_burn', 'total_events_daily_swap', 'total_events_daily' ]\n",
    "    df_all = pd.DataFrame(columns=columns_agg)\n",
    "    \n",
    "    for tag in tags:\n",
    "        print('Computing aggregation data for '+agg_type, tag)\n",
    "        # Select data type: e.g., STRK_USDC_Mint, ETH_USDC_Burn, STRK_ETH_Swap, ... etc\n",
    "        df2 = df[df['tag']==tag]\n",
    "        df_agg_tmp = pd.DataFrame(columns=columns_agg)   # create a temporal dataframe\n",
    "\n",
    "        # First, seperate into daily dataframe\n",
    "        datetime_range = _generate_datetime_range(df2, agg_type)  # create either daily or hourly agg data\n",
    "        \n",
    "        for dt in datetime_range:\n",
    "            if agg_type == 'daily':\n",
    "                # Select data within a certain day\n",
    "                df2_input = df2[df2['datetime'].dt.date == dt.date()] \n",
    "            elif agg_type == 'hourly':\n",
    "                # Select data within a certain hour of a certain day\n",
    "                df2_input = df2[ (df2['datetime'].dt.date == dt.date()) & (df2['datetime'].dt.hour == dt.hour) ]   \n",
    "                \n",
    "            if len(df2_input)>0:\n",
    "                df_new = _generate_aggregation(df2_input, columns_agg, tag, agg_type)   # Compute aggregation values\n",
    "                df_agg_tmp = pd.concat([df_agg_tmp, df_new])\n",
    "                df_agg_tmp = df_agg_tmp.reset_index(drop=True)\n",
    "    \n",
    "        df_all = pd.concat([df_all, df_agg_tmp])\n",
    "        \n",
    "    df_all = df_all.sort_values(by='timestamp')\n",
    "    df_all = df_all.reset_index(drop=True)\n",
    "    \n",
    "    df_all.to_csv('df_agg_'+agg_type+'_all.csv')\n",
    "    print('End of Computing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "475739a0-62ba-4da6-a1f1-fabacd36b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ETH_USDC' 'USDC_USDT' 'STRK_ETH' 'STRK_USDC' 'STRK_USDT']\n",
      "Computing aggregation data for daily ETH_USDC\n",
      "Computing aggregation data for daily USDC_USDT\n",
      "Computing aggregation data for daily STRK_ETH\n",
      "Computing aggregation data for daily STRK_USDC\n",
      "Computing aggregation data for daily STRK_USDT\n",
      "End of Computing\n",
      "Total execution time: 2.63 minutes\n",
      "['STRK_ETH', 'STRK_USDC', 'STRK_USDT']\n",
      "Computing aggregation data for hourly STRK_ETH\n",
      "Computing aggregation data for hourly STRK_USDC\n",
      "Computing aggregation data for hourly STRK_USDT\n",
      "End of Computing\n",
      "Total execution time: 0.63 minutes\n"
     ]
    }
   ],
   "source": [
    "# Compute daily aggregation data\n",
    "tags_daily = df['tag'].unique()\n",
    "print(tags_daily)\n",
    "start_time = time.time()\n",
    "#######\n",
    "create_aggregation_table(df, tags_daily, 'daily')\n",
    "#######\n",
    "end_time = time.time()\n",
    "print(\"Total execution time:\", round((end_time - start_time)/60, 2), \"minutes\")\n",
    "\n",
    "\n",
    "# Compute hourly aggregation data\n",
    "tags_hourly = ['STRK_ETH', 'STRK_USDC', 'STRK_USDT']\n",
    "print(tags_hourly)  \n",
    "\n",
    "start_time = time.time()\n",
    "#######\n",
    "create_aggregation_table(df, tags_hourly, 'hourly')\n",
    "#######\n",
    "end_time = time.time()\n",
    "print(\"Total execution time:\", round((end_time - start_time)/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3543445c-76dc-4506-a3bf-241925a1939e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to  df_agg_daily_ETH_USDC.csv\n",
      "Saved to  df_agg_daily_USDC_USDT.csv\n",
      "Saved to  df_agg_daily_STRK_ETH.csv\n",
      "Saved to  df_agg_daily_STRK_USDC.csv\n",
      "Saved to  df_agg_daily_STRK_USDT.csv\n",
      "Saved to  df_agg_hourly_STRK_ETH.csv\n",
      "Saved to  df_agg_hourly_STRK_USDC.csv\n",
      "Saved to  df_agg_hourly_STRK_USDT.csv\n"
     ]
    }
   ],
   "source": [
    "# Save individual files for ETH/USDC, USDC/USDT, STRK/ETH, STRK/USDC, STRK/USDT\n",
    "for tag in tags_daily:\n",
    "    df_daily = pd.read_csv('df_agg_daily_all.csv')\n",
    "    dfn = df_daily[df_daily['tag']==tag]\n",
    "    dfn.to_csv('df_agg_daily_'+tag+'.csv')\n",
    "    print('Saved to ', 'df_agg_daily_'+tag+'.csv')\n",
    "\n",
    "for tag in tags_hourly:\n",
    "    df_hourly = pd.read_csv('df_agg_hourly_all.csv')\n",
    "    dfn = df_hourly[df_hourly['tag']==tag]\n",
    "    dfn.to_csv('df_agg_hourly_'+tag+'.csv')\n",
    "    print('Saved to ', 'df_agg_hourly_'+tag+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
